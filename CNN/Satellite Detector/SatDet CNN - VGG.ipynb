{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce188236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset\n",
    "%matplotlib inline\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.io import read_image\n",
    "import torch.optim as optim\n",
    "\n",
    "class SatellitesDetectorDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform: \n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "tranform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                     transforms.Resize((224,224)), \n",
    "                                     transforms.RandomHorizontalFlip(p=0.7), \n",
    "                                     transforms.ToTensor(), \n",
    "                                     transforms.Normalize(mean=[0.449], std=[0.226])])\n",
    "tranform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.Resize((224,224)), \n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize(mean=[0.449], std=[0.226])])\n",
    "\n",
    "#preparing the train, validation and test dataset\n",
    "torch.manual_seed(43)\n",
    "train_ds = SatellitesDetectorDataset(annotations_file='D:/Documents/CNN/Satellite Detector/SatellitesDataset/sd_labels.csv',\n",
    "                                     img_dir='D:/Documents/CNN/Satellite Detector/SatellitesDataset/satellites_data/', \n",
    "                                     transform=tranform_train)\n",
    "val_size = 100\n",
    "train_size = len(train_ds) - val_size\n",
    "train_ds, val_ds = random_split(train_ds, [train_size, val_size])\n",
    "test_ds = SatellitesDetectorDataset(annotations_file='D:/Documents/CNN/Satellite Detector/SatellitesDataset/sd_labels.csv',\n",
    "                                     img_dir='D:/Documents/CNN/Satellite Detector/SatellitesDataset/satellites_data/', \n",
    "                                     transform=tranform_test)\n",
    "\n",
    "#passing the train, val and test datasets to the dataloader\n",
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=16, shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Convolutional Neural Network vgg16\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(25088, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = VGG16()\n",
    "\n",
    "# PREPARE THE MODEL FOR TRAINING\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #training with either cpu or cuda\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "model = VGG16() #to compile the model\n",
    "model = model.to(device=device) #to send the model for training on either cuda or cpu\n",
    "\n",
    "## Loss and optimizer\n",
    "learning_rate = 1e-4 #I picked this because it seems to be the most used by experts\n",
    "load_model = True\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr= learning_rate) #Adam seems to be the most popular for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TRAINING\n",
    "\n",
    "for epoch in range(35): #I decided to train the model for 50 epochs\n",
    "    loss_ep = 0\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_dl):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        ## Forward Pass\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ep += loss.item()\n",
    "    print(f\"Loss in epoch {epoch} :::: {loss_ep/len(train_dl)}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        for batch_idx, (data,targets) in enumerate(val_dl):\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            ## Forward Pass\n",
    "            scores = model(data)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == targets).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b5003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING THE MODEL AND USING IT FOR THE TEST SET\n",
    "\n",
    "torch.save(model.state_dict(), \"vgg16_cifar.pt\") #SAVES THE TRAINED MODEL\n",
    "\n",
    "model = VGG16()\n",
    "model.load_state_dict(torch.load(\"vgg16_cifar.pt\")) #loads the trained model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe14012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "\n",
    "num_correct = 0\n",
    "num_samples = 0\n",
    "for batch_idx, (data,targets) in enumerate(test_dl):\n",
    "    data = data.to(device=\"cpu\")\n",
    "    targets = targets.to(device=\"cpu\")\n",
    "    ## Forward Pass\n",
    "    scores = model(data)\n",
    "    _, predictions = scores.max(1)\n",
    "    num_correct += (predictions == targets).sum()\n",
    "    num_samples += predictions.size(0)\n",
    "print(\n",
    "    f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
