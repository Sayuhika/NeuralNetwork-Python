{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dff2c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# importing the libraries and downloading cifar-10\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "%matplotlib inline\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "\n",
    "# https://github.com/Ti-Oluwanimi/Neural-Network-Classification-Algorithms/blob/main/VGG16.ipynb\n",
    "\n",
    "tranform_train = transforms.Compose([transforms.Resize((56,56)), transforms.RandomHorizontalFlip(p=0.7), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "tranform_test = transforms.Compose([transforms.Resize((56,56)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "#preparing the train, validation and test dataset\n",
    "torch.manual_seed(43)\n",
    "train_ds = CIFAR10(\"data/\", train=True, download=True, transform=tranform_train) #40,000 original images + transforms\n",
    "val_size = 10000 #there are 10,000 test images and since there are no transforms performed on the test, we keep the validation as 10,000\n",
    "train_size = len(train_ds) - val_size\n",
    "train_ds, val_ds = random_split(train_ds, [train_size, val_size]) #Extracting the 10,000 validation images from the train set\n",
    "test_ds = CIFAR10(\"data/\", train=False, download=True, transform=tranform_test) #10,000 images\n",
    "\n",
    "#passing the train, val and test datasets to the dataloader\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define a Convolutional Neural Network vgg16\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        #self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        #self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        #self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        #self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        #self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        #self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(12544, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        #x = F.relu(self.conv4_1(x))\n",
    "        #x = F.relu(self.conv4_2(x))\n",
    "        #x = F.relu(self.conv4_3(x))\n",
    "        #x = self.maxpool(x)\n",
    "        #x = F.relu(self.conv5_1(x))\n",
    "        #x = F.relu(self.conv5_2(x))\n",
    "        #x = F.relu(self.conv5_3(x))\n",
    "        #x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = VGG16()\n",
    "\n",
    "# PREPARE THE MODEL FOR TRAINING\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #training with either cpu or cuda\n",
    "\n",
    "model = VGG16() #to compile the model\n",
    "model = model.to(device=device) #to send the model for training on either cuda or cpu\n",
    "\n",
    "## Loss and optimizer\n",
    "learning_rate = 1e-4 #I picked this because it seems to be the most used by experts\n",
    "load_model = True\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr= learning_rate) #Adam seems to be the most popular for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c6792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 :::: 1.7377256494522095\n",
      "Got 4762 / 10000 with accuracy 47.62\n",
      "Loss in epoch 1 :::: 1.3163662883758545\n",
      "Got 5559 / 10000 with accuracy 55.59\n",
      "Loss in epoch 2 :::: 1.1057202085494995\n",
      "Got 6249 / 10000 with accuracy 62.49\n",
      "Loss in epoch 3 :::: 0.9365816151618958\n",
      "Got 6525 / 10000 with accuracy 65.25\n",
      "Loss in epoch 4 :::: 0.8113512804508209\n",
      "Got 6770 / 10000 with accuracy 67.70\n",
      "Loss in epoch 5 :::: 0.7095875535011291\n",
      "Got 7145 / 10000 with accuracy 71.45\n",
      "Loss in epoch 6 :::: 0.6168288852214813\n",
      "Got 7263 / 10000 with accuracy 72.63\n",
      "Loss in epoch 7 :::: 0.5338052457332612\n",
      "Got 7402 / 10000 with accuracy 74.02\n",
      "Loss in epoch 8 :::: 0.4537640543937683\n",
      "Got 7437 / 10000 with accuracy 74.37\n",
      "Loss in epoch 9 :::: 0.38076443392038345\n",
      "Got 7577 / 10000 with accuracy 75.77\n",
      "Loss in epoch 10 :::: 0.32575270504951476\n",
      "Got 7534 / 10000 with accuracy 75.34\n",
      "Loss in epoch 11 :::: 0.27313885802030563\n",
      "Got 7647 / 10000 with accuracy 76.47\n",
      "Loss in epoch 12 :::: 0.23642854266166688\n",
      "Got 7657 / 10000 with accuracy 76.57\n",
      "Loss in epoch 13 :::: 0.20686708510518073\n",
      "Got 7620 / 10000 with accuracy 76.20\n",
      "Loss in epoch 14 :::: 0.17117677926719188\n",
      "Got 7693 / 10000 with accuracy 76.93\n",
      "Loss in epoch 15 :::: 0.1496431518793106\n",
      "Got 7657 / 10000 with accuracy 76.57\n",
      "Loss in epoch 16 :::: 0.13507848572731018\n",
      "Got 7650 / 10000 with accuracy 76.50\n",
      "Loss in epoch 17 :::: 0.12420174627900124\n",
      "Got 7662 / 10000 with accuracy 76.62\n",
      "Loss in epoch 18 :::: 0.11808039777427912\n",
      "Got 7701 / 10000 with accuracy 77.01\n",
      "Loss in epoch 19 :::: 0.10550822560638189\n",
      "Got 7643 / 10000 with accuracy 76.43\n",
      "Loss in epoch 20 :::: 0.09772446590960025\n",
      "Got 7679 / 10000 with accuracy 76.79\n",
      "Loss in epoch 21 :::: 0.09081290939599275\n",
      "Got 7741 / 10000 with accuracy 77.41\n",
      "Loss in epoch 22 :::: 0.08204295965135097\n",
      "Got 7660 / 10000 with accuracy 76.60\n",
      "Loss in epoch 23 :::: 0.07493229397833347\n",
      "Got 7719 / 10000 with accuracy 77.19\n",
      "Loss in epoch 24 :::: 0.0767254050500691\n",
      "Got 7681 / 10000 with accuracy 76.81\n",
      "Loss in epoch 25 :::: 0.07159609114602208\n",
      "Got 7709 / 10000 with accuracy 77.09\n",
      "Loss in epoch 26 :::: 0.06792668640762567\n",
      "Got 7707 / 10000 with accuracy 77.07\n",
      "Loss in epoch 27 :::: 0.0663056254254654\n",
      "Got 7670 / 10000 with accuracy 76.70\n",
      "Loss in epoch 28 :::: 0.0609573122292757\n",
      "Got 7671 / 10000 with accuracy 76.71\n",
      "Loss in epoch 29 :::: 0.05765464595146477\n",
      "Got 7757 / 10000 with accuracy 77.57\n",
      "Loss in epoch 30 :::: 0.05961222906783223\n",
      "Got 7578 / 10000 with accuracy 75.78\n",
      "Loss in epoch 31 :::: 0.052089851461164655\n",
      "Got 7738 / 10000 with accuracy 77.38\n",
      "Loss in epoch 32 :::: 0.05206055517252535\n",
      "Got 7706 / 10000 with accuracy 77.06\n",
      "Loss in epoch 33 :::: 0.04714058980252594\n",
      "Got 7732 / 10000 with accuracy 77.32\n",
      "Loss in epoch 34 :::: 0.04809037715159357\n",
      "Got 7758 / 10000 with accuracy 77.58\n"
     ]
    }
   ],
   "source": [
    "#  TRAINING\n",
    "\n",
    "for epoch in range(35): #I decided to train the model for 50 epochs\n",
    "    loss_ep = 0\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_dl):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        ## Forward Pass\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ep += loss.item()\n",
    "    print(f\"Loss in epoch {epoch} :::: {loss_ep/len(train_dl)}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        for batch_idx, (data,targets) in enumerate(val_dl):\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            ## Forward Pass\n",
    "            scores = model(data)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == targets).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\")\n",
    "        \n",
    "# SAVING THE MODEL\n",
    "torch.save(model.state_dict(), \"vgg16_cifar_mod32x32.pt\") #SAVES THE TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eea1191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 7670 / 10000 with accuracy 76.70\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "model = VGG16()\n",
    "model.load_state_dict(torch.load(\"vgg16_cifar_mod32x32.pt\")) #loads the trained model\n",
    "model.eval()\n",
    "\n",
    "num_correct = 0\n",
    "num_samples = 0\n",
    "for batch_idx, (data,targets) in enumerate(test_dl):\n",
    "    data = data.to(device=\"cpu\")\n",
    "    targets = targets.to(device=\"cpu\")\n",
    "    ## Forward Pass\n",
    "    scores = model(data)\n",
    "    _, predictions = scores.max(1)\n",
    "    num_correct += (predictions == targets).sum()\n",
    "    num_samples += predictions.size(0)\n",
    "print(\n",
    "    f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a244a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
