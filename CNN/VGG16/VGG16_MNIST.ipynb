{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7719e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries and downloading MNIST\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "%matplotlib inline\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "\n",
    "# https://github.com/Ti-Oluwanimi/Neural-Network-Classification-Algorithms/blob/main/VGG16.ipynb\n",
    "\n",
    "tranform_train = transforms.Compose([transforms.Resize((28,28)), transforms.RandomHorizontalFlip(p=0.7), transforms.ToTensor(), transforms.Normalize(mean=[0.449], std=[0.226])])\n",
    "tranform_test = transforms.Compose([transforms.Resize((28,28)), transforms.ToTensor(), transforms.Normalize(mean=[0.449], std=[0.226])])\n",
    "\n",
    "#preparing the train, validation and test dataset\n",
    "torch.manual_seed(43)\n",
    "train_ds = MNIST(\"data/\", train=True, download=True, transform=tranform_train) #40,000 original images + transforms\n",
    "val_size = 10000 #there are 10,000 test images and since there are no transforms performed on the test, we keep the validation as 10,000\n",
    "train_size = len(train_ds) - val_size\n",
    "train_ds, val_ds = random_split(train_ds, [train_size, val_size]) #Extracting the 10,000 validation images from the train set\n",
    "test_ds = MNIST(\"data/\", train=False, download=True, transform=tranform_test) #10,000 images\n",
    "\n",
    "#passing the train, val and test datasets to the dataloader\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41da2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Convolutional Neural Network vgg16\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        #self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        #self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        #self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        #self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        #self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        #self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        #self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        #self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        #self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        #self.fc1 = nn.Linear(25088, 4096)\n",
    "        #self.fc2 = nn.Linear(4096, 4096)\n",
    "        #self.fc3 = nn.Linear(4096, 10)\n",
    "        self.fc1 = nn.Linear(6272, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        #x = F.relu(self.conv3_1(x))\n",
    "        #x = F.relu(self.conv3_2(x))\n",
    "        #x = F.relu(self.conv3_3(x))\n",
    "        #x = self.maxpool(x)\n",
    "        #x = F.relu(self.conv4_1(x))\n",
    "        #x = F.relu(self.conv4_2(x))\n",
    "        #x = F.relu(self.conv4_3(x))\n",
    "        #x = self.maxpool(x)\n",
    "        #x = F.relu(self.conv5_1(x))\n",
    "        #x = F.relu(self.conv5_2(x))\n",
    "        #x = F.relu(self.conv5_3(x))\n",
    "        #x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = VGG16()\n",
    "\n",
    "# PREPARE THE MODEL FOR TRAINING\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #training with either cpu or cuda\n",
    "\n",
    "model = VGG16() #to compile the model\n",
    "model = model.to(device=device) #to send the model for training on either cuda or cpu\n",
    "\n",
    "## Loss and optimizer\n",
    "learning_rate = 1e-4 #I picked this because it seems to be the most used by experts\n",
    "load_model = True\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr= learning_rate) #Adam seems to be the most popular for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42765002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 :::: 0.3928683835462508\n",
      "Got 9546 / 10000 with accuracy 95.46\n",
      "Loss in epoch 1 :::: 0.11401461648359425\n",
      "Got 9712 / 10000 with accuracy 97.12\n",
      "Loss in epoch 2 :::: 0.07967677496606633\n",
      "Got 9749 / 10000 with accuracy 97.49\n",
      "Loss in epoch 3 :::: 0.06358959705641694\n",
      "Got 9775 / 10000 with accuracy 97.75\n",
      "Loss in epoch 4 :::: 0.05370984028637384\n",
      "Got 9816 / 10000 with accuracy 98.16\n",
      "Loss in epoch 5 :::: 0.04332143656055958\n",
      "Got 9825 / 10000 with accuracy 98.25\n",
      "Loss in epoch 6 :::: 0.03869320734728294\n",
      "Got 9824 / 10000 with accuracy 98.24\n",
      "Loss in epoch 7 :::: 0.033039784136689995\n",
      "Got 9839 / 10000 with accuracy 98.39\n",
      "Loss in epoch 8 :::: 0.030479409253112523\n",
      "Got 9858 / 10000 with accuracy 98.58\n",
      "Loss in epoch 9 :::: 0.025890346577746276\n",
      "Got 9869 / 10000 with accuracy 98.69\n",
      "Loss in epoch 10 :::: 0.02334509712599288\n",
      "Got 9860 / 10000 with accuracy 98.60\n",
      "Loss in epoch 11 :::: 0.021677658466756938\n",
      "Got 9866 / 10000 with accuracy 98.66\n",
      "Loss in epoch 12 :::: 0.02088167352726664\n",
      "Got 9875 / 10000 with accuracy 98.75\n",
      "Loss in epoch 13 :::: 0.018911431691782197\n",
      "Got 9889 / 10000 with accuracy 98.89\n",
      "Loss in epoch 14 :::: 0.016470531904101308\n",
      "Got 9892 / 10000 with accuracy 98.92\n",
      "Loss in epoch 15 :::: 0.01542344018342745\n",
      "Got 9889 / 10000 with accuracy 98.89\n",
      "Loss in epoch 16 :::: 0.01358420905297349\n",
      "Got 9889 / 10000 with accuracy 98.89\n",
      "Loss in epoch 17 :::: 0.014494297911747079\n",
      "Got 9885 / 10000 with accuracy 98.85\n",
      "Loss in epoch 18 :::: 0.012467244880641928\n",
      "Got 9869 / 10000 with accuracy 98.69\n",
      "Loss in epoch 19 :::: 0.011912240562208059\n",
      "Got 9900 / 10000 with accuracy 99.00\n",
      "Loss in epoch 20 :::: 0.010279585801997268\n",
      "Got 9886 / 10000 with accuracy 98.86\n",
      "Loss in epoch 21 :::: 0.010701866405957551\n",
      "Got 9886 / 10000 with accuracy 98.86\n",
      "Loss in epoch 22 :::: 0.009962983830886615\n",
      "Got 9895 / 10000 with accuracy 98.95\n",
      "Loss in epoch 23 :::: 0.008221396063826535\n",
      "Got 9886 / 10000 with accuracy 98.86\n",
      "Loss in epoch 24 :::: 0.01002187961090962\n",
      "Got 9902 / 10000 with accuracy 99.02\n",
      "Loss in epoch 25 :::: 0.009898798192966145\n",
      "Got 9903 / 10000 with accuracy 99.03\n",
      "Loss in epoch 26 :::: 0.0075712106424428325\n",
      "Got 9895 / 10000 with accuracy 98.95\n",
      "Loss in epoch 27 :::: 0.006749830772217698\n",
      "Got 9883 / 10000 with accuracy 98.83\n",
      "Loss in epoch 28 :::: 0.007678675258560072\n",
      "Got 9895 / 10000 with accuracy 98.95\n",
      "Loss in epoch 29 :::: 0.007076866111365688\n",
      "Got 9895 / 10000 with accuracy 98.95\n",
      "Loss in epoch 30 :::: 0.007131569751301308\n",
      "Got 9889 / 10000 with accuracy 98.89\n",
      "Loss in epoch 31 :::: 0.007421154189647655\n",
      "Got 9906 / 10000 with accuracy 99.06\n",
      "Loss in epoch 32 :::: 0.005586894557034012\n",
      "Got 9882 / 10000 with accuracy 98.82\n",
      "Loss in epoch 33 :::: 0.006087118577186825\n",
      "Got 9905 / 10000 with accuracy 99.05\n",
      "Loss in epoch 34 :::: 0.006343945189827451\n",
      "Got 9893 / 10000 with accuracy 98.93\n"
     ]
    }
   ],
   "source": [
    "#  TRAINING\n",
    "\n",
    "for epoch in range(35): #I decided to train the model for 50 epochs\n",
    "    loss_ep = 0\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_dl):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        ## Forward Pass\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ep += loss.item()\n",
    "    print(f\"Loss in epoch {epoch} :::: {loss_ep/len(train_dl)}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        for batch_idx, (data,targets) in enumerate(val_dl):\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            ## Forward Pass\n",
    "            scores = model(data)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == targets).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c77e6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG16(\n",
       "  (conv1_1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=6272, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (fc3): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAVING THE MODEL AND USING IT FOR THE TEST SET\n",
    "\n",
    "torch.save(model.state_dict(), \"vgg16_mnist.pt\") #SAVES THE TRAINED MODEL\n",
    "\n",
    "model = VGG16()\n",
    "model.load_state_dict(torch.load(\"vgg16_mnist.pt\")) #loads the trained model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c9b93de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9882 / 10000 with accuracy 98.82\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "\n",
    "num_correct = 0\n",
    "num_samples = 0\n",
    "for batch_idx, (data,targets) in enumerate(test_dl):\n",
    "    data = data.to(device=\"cpu\")\n",
    "    targets = targets.to(device=\"cpu\")\n",
    "    ## Forward Pass\n",
    "    scores = model(data)\n",
    "    _, predictions = scores.max(1)\n",
    "    num_correct += (predictions == targets).sum()\n",
    "    num_samples += predictions.size(0)\n",
    "print(\n",
    "    f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff5aa08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
